{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport os\nimport ast\nfrom pathlib import Path\nimport datasets\nfrom PIL import Image\nimport pandas as pd\n\nlogger = datasets.logging.get_logger(__name__)\n_CITATION = \"\"\"\\\n@article{,\n  title={},\n  author={},\n  journal={},\n  year={},\n  volume={}\n}\n\"\"\"\n_DESCRIPTION = \"\"\"\\\nThis is a sample dataset for training layoutlmv3 model on custom annotated data.\n\"\"\"\n\ndef load_image(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    w, h = image.size\n    return image, (w,h)\n\ndef normalize_bbox(bbox, size):\n    return [\n        int(1000 * bbox[0] / size[0]),\n        int(1000 * bbox[1] / size[1]),\n        int(1000 * bbox[2] / size[0]),\n        int(1000 * bbox[3] / size[1]),\n    ]\n\n\n_URLS = []\n\n'''Edit your working directory folder path here if required. \nIf this file is in the same folder as the \"layoutlmv3\" folder keep it as it is.\n'''\ndata_path = r'/kaggle/input/layoutlmv3-data3' \n\nclass DatasetConfig(datasets.BuilderConfig):\n    \"\"\"BuilderConfig for InvoiceExtraction Dataset\"\"\"\n    def __init__(self, **kwargs):\n        \"\"\"BuilderConfig for InvoiceExtraction Dataset.\n        Args:\n          **kwargs: keyword arguments forwarded to super.\n        \"\"\"\n        super(DatasetConfig, self).__init__(**kwargs)\n\n\nclass InvoiceExtraction(datasets.GeneratorBasedBuilder):\n    BUILDER_CONFIGS = [\n        DatasetConfig(name=\"InvoiceExtraction\", version=datasets.Version(\"1.0.0\"), description=\"InvoiceExtraction dataset\"),\n    ]\n\n    def _info(self):\n        return datasets.DatasetInfo(\n            description=_DESCRIPTION,\n            features=datasets.Features(\n                {\n                    \"id\": datasets.Value(\"string\"),\n                    \"tokens\": datasets.Sequence(datasets.Value(\"string\")),\n                    \"bboxes\": datasets.Sequence(datasets.Sequence(datasets.Value(\"int64\"))),\n                    \"ner_tags\": datasets.Sequence(\n                        datasets.features.ClassLabel(\n                            names = ['invoice_no', 'invoice_date', 'due_date', 'total_amount', 'item', 'gst'] #Enter the list of labels that you have here.\n                            )\n                    ),\n                    \"image_path\": datasets.Value(\"string\"),\n                    \"image\": datasets.features.Image()\n                }\n            ),\n            supervised_keys=None,\n            citation=_CITATION,\n            homepage=\"\",\n        )\n\n\n\n\n    def _split_generators(self, dl_manager):\n        \"\"\"Returns SplitGenerators.\"\"\"\n        \"\"\"Uses local files located with data_dir\"\"\"\n        dest = os.path.join(data_path, 'layoutlmv3')\n\n        return [\n            datasets.SplitGenerator(\n                name=datasets.Split.TRAIN, gen_kwargs={\"filepath\": os.path.join(dest, \"train.txt\"), \"dest\": dest}\n            ),            \n            datasets.SplitGenerator(\n                name=datasets.Split.TEST, gen_kwargs={\"filepath\": os.path.join(dest, \"test.txt\"), \"dest\": dest}\n            ),\n        ]\n\n    def _generate_examples(self, filepath, dest):\n\n        df = pd.read_csv(os.path.join(dest, 'class_list.txt'), sep=',', header=None)\n#         id2labels = dict(zip(df[0].tolist(), df[1].tolist()))\n        id2labels = dict(zip(df.columns.tolist(), df.iloc[0].tolist()))\n\n\n        logger.info(\"⏳ Generating examples from = %s\", filepath)\n\n        item_list = []\n        with open(filepath, 'r', encoding='utf-8') as f:\n            for line in f:\n                item_list.append(line.rstrip('\\n\\r'))\n#         print(item_list)\n        for guid, fname in enumerate(item_list):\n            print(fname)\n            data = ast.literal_eval(fname)\n            image_path = os.path.join(dest, data['file_name'])\n            image, size = load_image(image_path)\n            boxes = data['bboxes']\n\n            text = data['tokens']\n            label = data['ner_tags']\n            \n            #print(boxes)\n            #for i in boxes:\n            #  print(i)\n            boxes = [normalize_bbox(box, size) for box in boxes]\n            flag=0\n            #print(image_path)\n            for i in boxes:\n              #print(i)\n              for j in i:\n                if j>1000:\n                  flag+=1\n                  #print(j)\n                  pass\n            if flag>0: print(image_path)\n \n            yield guid, {\"id\": str(guid), \"tokens\": text, \"bboxes\": boxes, \"ner_tags\": label, \"image_path\": image_path, \"image\": image}","metadata":{"execution":{"iopub.status.busy":"2024-10-20T09:43:53.203208Z","iopub.execute_input":"2024-10-20T09:43:53.203797Z","iopub.status.idle":"2024-10-20T09:43:53.222550Z","shell.execute_reply.started":"2024-10-20T09:43:53.203760Z","shell.execute_reply":"2024-10-20T09:43:53.221240Z"},"trusted":true},"execution_count":2,"outputs":[]}]}